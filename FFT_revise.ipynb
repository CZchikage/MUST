{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhao-xingyuan/Hsubsampling/blob/main/FFT_revise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gx-CW2qj6qP",
        "outputId": "7af4df52-01a9-4f5e-ed72-d89c3d0b9f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'PLD-Accountant'...\n",
            "remote: Enumerating objects: 597, done.\u001b[K\n",
            "remote: Counting objects: 100% (294/294), done.\u001b[K\n",
            "remote: Compressing objects: 100% (197/197), done.\u001b[K\n",
            "remote: Total 597 (delta 159), reused 209 (delta 95), pack-reused 303\u001b[K\n",
            "Receiving objects: 100% (597/597), 482.42 KiB | 1.98 MiB/s, done.\n",
            "Resolving deltas: 100% (346/346), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DPBayes/PLD-Accountant.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k44u34YA_kJU",
        "outputId": "1ad8c860-8266-459b-9cbb-2d49f999ff0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fourier-accountant\n",
            "  Downloading fourier_accountant-0.12.11-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fourier-accountant) (1.22.4)\n",
            "Installing collected packages: fourier-accountant\n",
            "Successfully installed fourier-accountant-0.12.11\n"
          ]
        }
      ],
      "source": [
        "!pip3 install fourier-accountant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM4SR0Wcib9y"
      },
      "source": [
        "Reproduce delta and epsilon upper and lower bounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLvfGJl_ZCxF"
      },
      "outputs": [],
      "source": [
        "from abc import ABCMeta, abstractmethod, abstractproperty\n",
        "import typing\n",
        "import numpy as np\n",
        "import scipy.special\n",
        "import scipy.optimize\n",
        "from enum import Enum\n",
        "\n",
        "class NeighborRelation(Enum):\n",
        "    REMOVE_POISSON = 'remove-poisson'\n",
        "    SUBSTITUTE_NO_REPLACE = 'substitute-no-replace'\n",
        "    S_W_REPLACE =\"s-w-replace\"\n",
        "    S_H = \"s-h\"\n",
        "\n",
        "class PrivacyException(Exception):\n",
        "    \"\"\" An exception indicating a violation of privacy constraints. \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self, *args, **kwargs)\n",
        "\n",
        "class PrivacyLossDistribution(metaclass=ABCMeta):\n",
        "    \"\"\" The distribution of the privacy loss resulting from application\n",
        "    of a differentially private mechanism.\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_accountant_parameters(self, error_tolerance: float) -> typing.Tuple[float, float, int]:\n",
        "        \"\"\" Determines suitable hyperparameters for the Fourier accountant\n",
        "        for a given error tolerance.\n",
        "\n",
        "        Args:\n",
        "            - error_tolerance (float): The tolerance for error in approximations\n",
        "                of bounds for delta.\n",
        "\n",
        "        Returns:\n",
        "            - L: Bound for the privacy loss interval to evaluate.\n",
        "            - lambd: Parameter lambda for error bound computation.\n",
        "            - nx: Number of discretization bins.\n",
        "        \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def discretize_privacy_loss_distribution(self,\n",
        "            start: float, stop: float, num_discretisation_bins_half: int\n",
        "        ) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\" Computes the privacy loss probability mass function evaluated for\n",
        "        equally-sized discrete bins.\n",
        "\n",
        "        Args:\n",
        "            - start: Starting value for discretisation interval in privacy loss domain.\n",
        "            - stop: (Exclusive) end value for discretisation interval in privacy loss domain.\n",
        "            - num_discretisation_bins_half: The number of discretisation bins in the\n",
        "                interval, divided by 2.\n",
        "\n",
        "        Returns:\n",
        "            - omega_y_L: np.ndarray of size `number_of_discretisation_bins`\n",
        "                containing omega values for lower bound of delta.\n",
        "            - omega_y_R: np.ndarray of size `number_of_discretisation_bins`\n",
        "                containing omega values for upper bound of delta.\n",
        "            - Lx: np.ndarray of size `number_of_discretisation_bins`\n",
        "                containing the lower bound of the privacy loss intervals.\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afrl_VpMZLuB"
      },
      "outputs": [],
      "source": [
        "class SubsampledGaussianMechanism(PrivacyLossDistribution):\n",
        "    \"\"\" The privacy loss distribution of the subsampled Gaussian mechanism\n",
        "    with noise σ², subsampling ratio q.\n",
        "\n",
        "    It is assumed that the provided noise level corresponds to a sensitivity\n",
        "    of the mechanism of 1 in remove relation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "            sigma: float, q: typing.Optional[float] = 1., relation: NeighborRelation = NeighborRelation.REMOVE_POISSON\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            - sigma: Gaussian mechanism noise level for sensitivity 1.\n",
        "            - q: Subsampling ratio.\n",
        "            - relation: The neighboring relation for datasets.\n",
        "        \"\"\"\n",
        "        self.sigma = np.abs(sigma)\n",
        "        self.q = q\n",
        "        self._evaluate_internals = None\n",
        "        if self.q < 0 or self.q > 1:\n",
        "            raise ValueError(f\"Subsampling ratio q must be between 0 and 1, was {q}.\")\n",
        "        if relation == NeighborRelation.REMOVE_POISSON:\n",
        "            self._evaluate_internals = self._evaluate_internals_remove_relation\n",
        "        elif relation == NeighborRelation.SUBSTITUTE_NO_REPLACE:\n",
        "            self._evaluate_internals = self._evaluate_internals_substitute_relation\n",
        "        else:\n",
        "            raise ValueError(\"Unknown neighboring relation given.\")\n",
        "\n",
        "\n",
        "    def get_accountant_parameters(self, error_tolerance: float) -> typing.Tuple[float, float, int]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def discretize_privacy_loss_distribution(self,\n",
        "            start: float, stop: float, num_discretisation_bins_half: int\n",
        "        ) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        nx = int(2 * num_discretisation_bins_half)\n",
        "\n",
        "        Xn, dx = np.linspace(start, stop, nx+1, endpoint=True, retstep=True)\n",
        "        assert dx == (stop - start) / nx\n",
        "\n",
        "        fxs = self.evaluate(Xn) # privacy loss density evaluated at all intervals bounds, including both ends\n",
        "        # interval i corresponds to bounds [i, i+1]\n",
        "\n",
        "        # determine maximum value: since pld is unimodal,\n",
        "        # must be in the interval left or right of the largest boundary value\n",
        "        max_boundary_id = np.argmax(fxs)\n",
        "        max_domain_ids = (\n",
        "            np.maximum(0, max_boundary_id - 1),\n",
        "            np.minimum(nx - 1, max_boundary_id + 1)\n",
        "        )\n",
        "        max_domain = (np.maximum(np.log(1 - self.q), Xn[max_domain_ids[0]]), Xn[max_domain_ids[1]])\n",
        "        opt_result = scipy.optimize.minimize_scalar(\n",
        "            lambda x: -self.evaluate(x), bounds=max_domain, method='bounded'\n",
        "        )\n",
        "        assert opt_result.success\n",
        "        x_max = opt_result.x    # location of maximum privacy loss density value\n",
        "        fx_max = -opt_result.fun # maximum of privacy loss density\n",
        "        x_max_idx = int((x_max - start) // dx)\n",
        "        assert x_max_idx >= 0 and x_max_idx < nx\n",
        "\n",
        "        # Majorant for privacy loss density: Maximal value in the interval containing it\n",
        "        # and the bound closer to maximum in all other intervals.\n",
        "        omega_R = np.zeros(nx) # the max privacy loss density for each of the intervals;\n",
        "        omega_R[x_max_idx]      = fx_max\n",
        "        omega_R[:x_max_idx]     = fxs[1 : x_max_idx + 1]  # right boundaries for intervals before maximum\n",
        "        omega_R[x_max_idx + 1:] = fxs[x_max_idx + 1 : -1] # left boundaries for intervals after maximum\n",
        "\n",
        "        # Minorant for privacy loss density: smaller bound for interval containing the maximum\n",
        "        # and the bound farther from maximum in all other intervals.\n",
        "        omega_L = np.zeros(nx) # the min privacy loss density for each of the intervals\n",
        "        omega_L[x_max_idx]      = np.min(fxs[x_max_idx:x_max_idx + 2])\n",
        "        omega_L[:x_max_idx]     = fxs[:x_max_idx]     # left boundaries for intervals before maximum\n",
        "        omega_L[x_max_idx + 1:] = fxs[x_max_idx + 2:] # right boundaries for intervals after maximum\n",
        "\n",
        "        omega_R *= dx\n",
        "        omega_L *= dx\n",
        "\n",
        "        assert np.all(omega_R >= omega_L)\n",
        "\n",
        "        return omega_L, omega_R, Xn[:-1]\n",
        "\n",
        "    def _evaluate_internals_remove_relation(self,\n",
        "            x: typing.Sequence[float], compute_derivative: typing.Optional[bool]=False\n",
        "        ) -> typing.Union[np.array, typing.Tuple[np.array, np.array]]:\n",
        "        \"\"\" Computes common values for PLD and its derivative.\n",
        "\n",
        "        Args:\n",
        "            - x: Privacy loss values for which to compute the probability density.\n",
        "            - compute_derivative: If True, also outputs the derivative of the\n",
        "                PLD evaluated at `x`.\n",
        "        Returns:\n",
        "            - omega: np.ndarray containing the probability density values of\n",
        "                the PLD for each value in `x`\n",
        "            - domega: (Only if `compute_derivative` is `True`): np.ndarray containing\n",
        "                the values of the derivative of the probability density functions\n",
        "                evaluated at each value in `x`.\n",
        "        \"\"\"\n",
        "        sigma = self.sigma\n",
        "        q = self.q\n",
        "\n",
        "        mask = np.ones_like(x, dtype=bool)\n",
        "        if q < 1:\n",
        "            mask = x > np.log(1 - q)\n",
        "            # note(lumip): actually we'd be fine with q=1 computing log(1-q)=-inf\n",
        "            #   giving us the full mask, but numpy will spam warnings, which\n",
        "            #   would confuse users, therefore this construct is necessary\n",
        "\n",
        "        sigma_sq = sigma**2\n",
        "        exp_x = np.exp(x[mask])\n",
        "        exp_x_m_1mq = exp_x - (1 - q)\n",
        "\n",
        "        # g(s) in AISTATS2021 paper, Sec. 6.3\n",
        "        Linvx = sigma_sq * ( np.log(exp_x_m_1mq) - np.log(q) ) + 0.5\n",
        "\n",
        "        gauss_exp_term_1mq = np.exp(-Linvx**2 / (2 * sigma_sq))\n",
        "        gauss_exp_term_q   = np.exp(-(Linvx-1)**2 / (2 * sigma_sq))\n",
        "\n",
        "        # f(g(s)) in AISTATS2021 paper, Sec. 6.3\n",
        "        ALinvx = ( 1/np.sqrt(2 * np.pi * sigma_sq) ) * (\n",
        "            (1 - q) * gauss_exp_term_1mq + q  * gauss_exp_term_q\n",
        "        )\n",
        "\n",
        "        # g'(s)\n",
        "        dLinvx = sigma_sq * exp_x /  exp_x_m_1mq\n",
        "\n",
        "        omega = np.zeros_like(x)\n",
        "        omega[mask] = ALinvx * dLinvx\n",
        "\n",
        "        if not compute_derivative:\n",
        "            return omega\n",
        "\n",
        "        dALinvx = -( 1/(np.sqrt(2 * np.pi * sigma_sq) * sigma_sq) ) * (\n",
        "            (1 - q) * gauss_exp_term_1mq * Linvx + q * gauss_exp_term_q * (Linvx - 1)\n",
        "        )\n",
        "\n",
        "        ddLinvx = sigma_sq * exp_x * (q - 1) / exp_x_m_1mq**2\n",
        "\n",
        "        domega = np.zeros_like(x)\n",
        "        domega[mask] = dALinvx * dLinvx**2 + ALinvx * ddLinvx\n",
        "        return omega, domega\n",
        "\n",
        "    def _evaluate_internals_substitute_relation(self,\n",
        "            x: typing.Sequence[float], compute_derivative: typing.Optional[bool]=False\n",
        "        ) -> typing.Union[np.array, typing.Tuple[np.array, np.array]]:\n",
        "        sigma = self.sigma\n",
        "        q = self.q\n",
        "\n",
        "        mask = np.ones_like(x, dtype=bool)\n",
        "        if q < 1:\n",
        "            mask = x > np.log(1 - q)\n",
        "\n",
        "        sigma_sq = sigma**2\n",
        "        exp_x = np.exp(x[mask])\n",
        "\n",
        "        c = q * np.exp( -1 / (2 * sigma_sq) )\n",
        "        c_sq_exp_x_4 = 4 * c**2 * exp_x\n",
        "\n",
        "        sqrtpart = np.sqrt( ((1 - q) * (1 - exp_x))**2 + c_sq_exp_x_4 )\n",
        "        logpart = ( sqrtpart - (1 - q) * (1 - exp_x) ) / (2 * c)\n",
        "        assert np.all(logpart > 0.)\n",
        "        Linvx = sigma_sq * np.log(logpart) # L^{-1}(s)\n",
        "\n",
        "        # note: straightforward implementation of derivative dLinvx:\n",
        "        # dlogpart_left = ((1 - q) * exp_x) / (2 * c)\n",
        "        # dlogpart_right = c_sq_exp_x_4 - 2 * (1 - q)**2 * exp_x * (1 - exp_x)\n",
        "        # dlogpart_right /= (4 * c * sqrtpart)\n",
        "        # dLinvx = (sigma_sq / logpart) * (dlogpart_left + dlogpart_right)\n",
        "\n",
        "        # note: slightly massages implementation of derivative dLinvx:\n",
        "        dsqrtpart = c_sq_exp_x_4 - 2 * (1 - q)**2 * exp_x * (1 - exp_x)\n",
        "        dsqrtpart /= 2*sqrtpart\n",
        "        dlogpart = (1 - q) * exp_x + dsqrtpart # without factor 2*c\n",
        "        # note: outer derivative of log would now require division by logpart,\n",
        "        #       but for stability we multiply numerator and denominator by\n",
        "        #       sqrtpart + (1-q) * (1-exp_x) to get the below\n",
        "        dlogpart_multiplied = dlogpart * (sqrtpart + (1 - q) * (1 - exp_x))\n",
        "        dLinvx = sigma_sq * dlogpart_multiplied / c_sq_exp_x_4 # d/ds L^{-1}(s)\n",
        "\n",
        "        # f_X(L^{-1}(s)):\n",
        "        ALinvx = (1 / np.sqrt(2 * np.pi * sigma**2) ) * (\n",
        "                    (1 - q) * np.exp(-Linvx**2     / (2 * sigma_sq)) +\n",
        "                    q *       np.exp(-(Linvx-1)**2 / (2 * sigma_sq))\n",
        "            )\n",
        "\n",
        "        omega = np.zeros_like(x)\n",
        "        omega[mask] = ALinvx * dLinvx\n",
        "\n",
        "        if not compute_derivative:\n",
        "            return omega\n",
        "\n",
        "        raise NotImplementedError(\"Derivative for substitute relation currently not implemented.\")\n",
        "\n",
        "    def evaluate(self, x: typing.Sequence[float]) -> np.ndarray:\n",
        "        \"\"\" Evaluates the probability densitiy function.\n",
        "\n",
        "        Args:\n",
        "            - x: Privacy loss values for which to compute the probability density.\n",
        "        Returns:\n",
        "            np.ndarray containing the probability density values of\n",
        "                the PLD for each value in `x`\n",
        "        \"\"\"\n",
        "        return self._evaluate_internals(x, compute_derivative=False)\n",
        "\n",
        "    def evaluate_derivative(self, x: typing.Sequence[float]) -> np.ndarray:\n",
        "        \"\"\" Evaluates the derivative of the probability densitiy function.\n",
        "\n",
        "        Args:\n",
        "            - x: Privacy loss values for which to compute the derivate of the\n",
        "                probability density functions.\n",
        "        Returns:\n",
        "            np.ndarray containing the values of the derivative of the probability\n",
        "                densitiy function evaluated each value in `x`\n",
        "        \"\"\"\n",
        "        return self._evaluate_internals(x, compute_derivative=True)[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsS7avx-wi3W"
      },
      "outputs": [],
      "source": [
        "from pickle import TRUE\n",
        "class SubsampledGaussianWithReplace(PrivacyLossDistribution):\n",
        "    \"\"\" The privacy loss distribution of the subsampled Gaussian mechanism\n",
        "    with noise σ², subsampling size m, total sample size n \n",
        "\n",
        "    It is assumed that the provided noise level corresponds to a sensitivity\n",
        "    of the mechanism of 1 in remove relation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "            sigma: float, m: typing.Optional[int] = 10000, n: typing.Optional[int] = 10000, sizeb: typing.Optional[int] = 100, relation: NeighborRelation = NeighborRelation.S_W_REPLACE\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            - sigma: Gaussian mechanism noise level for sensitivity 1.\n",
        "            - m: Subsampling size.\n",
        "            - relation: The neighboring relation for datasets.\n",
        "        \"\"\"\n",
        "        self.sigma = np.abs(sigma)\n",
        "        self.m = m\n",
        "        self.n = n\n",
        "        self.sizeb = sizeb\n",
        "        self._evaluate_internals = None\n",
        "        if self.m < 0 or self.m > n:\n",
        "            raise ValueError(f\"Subsampling ratio must be between 0 and 1.\")\n",
        "        if relation == NeighborRelation.REMOVE_POISSON:\n",
        "            self._evaluate_internals = self._evaluate_internals_remove_relation\n",
        "        elif relation == NeighborRelation.SUBSTITUTE_NO_REPLACE:\n",
        "            self._evaluate_internals = self._evaluate_internals_substitute_relation\n",
        "        elif relation == NeighborRelation.S_W_REPLACE:\n",
        "            self._evaluate_internals = self._evaluate_internals_w_replace\n",
        "        elif relation == NeighborRelation.S_H:\n",
        "            self._evaluate_internals = self._evaluate_internals_s_h\n",
        "        else:\n",
        "            raise ValueError(\"Unknown neighboring relation given.\")\n",
        "\n",
        "\n",
        "    def get_accountant_parameters(self, error_tolerance: float) -> typing.Tuple[float, float, int]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def discretize_privacy_loss_distribution(self,\n",
        "            start: float, stop: float, num_discretisation_bins_half: int\n",
        "        ) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        nx = int(2 * num_discretisation_bins_half)\n",
        "\n",
        "        Xn, dx = np.linspace(start, stop, nx+1, endpoint=True, retstep=True)\n",
        "        assert dx == (stop - start) / nx\n",
        "\n",
        "        fxs =  self.evaluate(Xn) # privacy loss density evaluated at all intervals bounds, including both ends\n",
        "        # interval i corresponds to bounds [i, i+1]\n",
        "\n",
        "        # determine maximum value: since pld is unimodal,\n",
        "        # must be in the interval left or right of the largest boundary value\n",
        "        # checked f_X (mixture Gaussian) is unimodal for sampling with replacement in R simulation\n",
        "        max_boundary_id = np.argmax(fxs)\n",
        "        max_domain_ids = (\n",
        "            np.maximum(0, max_boundary_id - 1),\n",
        "            np.minimum(nx - 1, max_boundary_id + 1)\n",
        "        )\n",
        "        max_domain = (Xn[max_domain_ids[0]], Xn[max_domain_ids[1]])\n",
        "        opt_result = scipy.optimize.minimize_scalar(\n",
        "            lambda x: -self.evaluate(x), bounds=max_domain, method='bounded'\n",
        "        )\n",
        "        assert opt_result.success\n",
        "        x_max = opt_result.x    # location of maximum privacy loss density value\n",
        "        fx_max = -opt_result.fun # maximum of privacy loss density\n",
        "        x_max_idx = int((x_max - start) // dx)\n",
        "        assert x_max_idx >= 0 and x_max_idx < nx\n",
        "\n",
        "        # Majorant for privacy loss density: Maximal value in the interval containing it\n",
        "        # and the bound closer to maximum in all other intervals.\n",
        "        omega_R = np.zeros(nx) # the max privacy loss density for each of the intervals;\n",
        "        omega_R[x_max_idx]      = fx_max\n",
        "        omega_R[:x_max_idx]     = fxs[1 : x_max_idx + 1]  # right boundaries for intervals before maximum\n",
        "        omega_R[x_max_idx + 1:] = fxs[x_max_idx + 1 : -1] # left boundaries for intervals after maximum\n",
        "\n",
        "        # Minorant for privacy loss density: smaller bound for interval containing the maximum\n",
        "        # and the bound farther from maximum in all other intervals.\n",
        "        omega_L = np.zeros(nx) # the min privacy loss density for each of the intervals\n",
        "        omega_L[x_max_idx]      = np.min(fxs[x_max_idx:x_max_idx + 2])\n",
        "        omega_L[:x_max_idx]     = fxs[:x_max_idx]     # left boundaries for intervals before maximum\n",
        "        omega_L[x_max_idx + 1:] = fxs[x_max_idx + 2:] # right boundaries for intervals after maximum\n",
        "\n",
        "        omega_R *= dx\n",
        "        omega_L *= dx\n",
        "\n",
        "        assert np.all(omega_R >= omega_L)\n",
        "\n",
        "        return omega_L, omega_R, Xn[:-1]\n",
        "\n",
        "    def _evaluate_internals_remove_relation(self,\n",
        "            x: typing.Sequence[float], compute_derivative: typing.Optional[bool]=False\n",
        "        ) -> typing.Union[np.array, typing.Tuple[np.array, np.array]]:\n",
        "        \"\"\" Computes common values for PLD and its derivative.\n",
        "\n",
        "        Args:\n",
        "            - x: Privacy loss values for which to compute the probability density.\n",
        "            - compute_derivative: If True, also outputs the derivative of the\n",
        "                PLD evaluated at `x`.\n",
        "        Returns:\n",
        "            - omega: np.ndarray containing the probability density values of\n",
        "                the PLD for each value in `x`\n",
        "            - domega: (Only if `compute_derivative` is `True`): np.ndarray containing\n",
        "                the values of the derivative of the probability density functions\n",
        "                evaluated at each value in `x`.\n",
        "        \"\"\"\n",
        "        sigma = self.sigma\n",
        "        q = self.q\n",
        "\n",
        "        mask = np.ones_like(x, dtype=bool)\n",
        "        if q < 1:\n",
        "            mask = x > np.log(1 - q)\n",
        "            # note(lumip): actually we'd be fine with q=1 computing log(1-q)=-inf\n",
        "            #   giving us the full mask, but numpy will spam warnings, which\n",
        "            #   would confuse users, therefore this construct is necessary\n",
        "\n",
        "        sigma_sq = sigma**2\n",
        "        exp_x = np.exp(x[mask])\n",
        "        exp_x_m_1mq = exp_x - (1 - q)\n",
        "\n",
        "        # g(s) in AISTATS2021 paper, Sec. 6.3\n",
        "        Linvx = sigma_sq * ( np.log(exp_x_m_1mq) - np.log(q) ) + 0.5\n",
        "\n",
        "        gauss_exp_term_1mq = np.exp(-Linvx**2 / (2 * sigma_sq))\n",
        "        gauss_exp_term_q   = np.exp(-(Linvx-1)**2 / (2 * sigma_sq))\n",
        "\n",
        "        # f(g(s)) in AISTATS2021 paper, Sec. 6.3\n",
        "        ALinvx = ( 1/np.sqrt(2 * np.pi * sigma_sq) ) * (\n",
        "            (1 - q) * gauss_exp_term_1mq + q  * gauss_exp_term_q\n",
        "        )\n",
        "\n",
        "        # g'(s)\n",
        "        dLinvx = sigma_sq * exp_x /  exp_x_m_1mq\n",
        "\n",
        "        omega = np.zeros_like(x)\n",
        "        omega[mask] = ALinvx * dLinvx\n",
        "\n",
        "        if not compute_derivative:\n",
        "            return omega\n",
        "\n",
        "        dALinvx = -( 1/(np.sqrt(2 * np.pi * sigma_sq) * sigma_sq) ) * (\n",
        "            (1 - q) * gauss_exp_term_1mq * Linvx + q * gauss_exp_term_q * (Linvx - 1)\n",
        "        )\n",
        "\n",
        "        ddLinvx = sigma_sq * exp_x * (q - 1) / exp_x_m_1mq**2\n",
        "\n",
        "        domega = np.zeros_like(x)\n",
        "        domega[mask] = dALinvx * dLinvx**2 + ALinvx * ddLinvx\n",
        "        return omega, domega\n",
        "\n",
        "    def _evaluate_internals_substitute_relation(self,\n",
        "            x: typing.Sequence[float], compute_derivative: typing.Optional[bool]=False\n",
        "        ) -> typing.Union[np.array, typing.Tuple[np.array, np.array]]:\n",
        "        sigma = self.sigma\n",
        "        q = self.q\n",
        "\n",
        "        mask = np.ones_like(x, dtype=bool)\n",
        "        if q < 1:\n",
        "            mask = x > np.log(1 - q)\n",
        "\n",
        "        sigma_sq = sigma**2\n",
        "        exp_x = np.exp(x[mask])\n",
        "\n",
        "        c = q * np.exp( -1 / (2 * sigma_sq) )\n",
        "        c_sq_exp_x_4 = 4 * c**2 * exp_x\n",
        "\n",
        "        sqrtpart = np.sqrt( ((1 - q) * (1 - exp_x))**2 + c_sq_exp_x_4 )\n",
        "        logpart = ( sqrtpart - (1 - q) * (1 - exp_x) ) / (2 * c)\n",
        "        assert np.all(logpart > 0.)\n",
        "        Linvx = sigma_sq * np.log(logpart) # L^{-1}(s)\n",
        "\n",
        "        # note: straightforward implementation of derivative dLinvx:\n",
        "        # dlogpart_left = ((1 - q) * exp_x) / (2 * c)\n",
        "        # dlogpart_right = c_sq_exp_x_4 - 2 * (1 - q)**2 * exp_x * (1 - exp_x)\n",
        "        # dlogpart_right /= (4 * c * sqrtpart)\n",
        "        # dLinvx = (sigma_sq / logpart) * (dlogpart_left + dlogpart_right)\n",
        "\n",
        "        # note: slightly massages implementation of derivative dLinvx:\n",
        "        dsqrtpart = c_sq_exp_x_4 - 2 * (1 - q)**2 * exp_x * (1 - exp_x)\n",
        "        dsqrtpart /= 2*sqrtpart\n",
        "        dlogpart = (1 - q) * exp_x + dsqrtpart # without factor 2*c\n",
        "        # note: outer derivative of log would now require division by logpart,\n",
        "        #       but for stability we multiply numerator and denominator by\n",
        "        #       sqrtpart + (1-q) * (1-exp_x) to get the below\n",
        "        dlogpart_multiplied = dlogpart * (sqrtpart + (1 - q) * (1 - exp_x))\n",
        "        dLinvx = sigma_sq * dlogpart_multiplied / c_sq_exp_x_4 # d/ds L^{-1}(s)\n",
        "\n",
        "        # f_X(L^{-1}(s)):\n",
        "        ALinvx = (1 / np.sqrt(2 * np.pi * sigma**2) ) * (\n",
        "                    (1 - q) * np.exp(-Linvx**2     / (2 * sigma_sq)) +\n",
        "                    q *       np.exp(-(Linvx-1)**2 / (2 * sigma_sq))\n",
        "            )\n",
        "\n",
        "        omega = np.zeros_like(x)\n",
        "        omega[mask] = ALinvx * dLinvx\n",
        "\n",
        "        if not compute_derivative:\n",
        "            return omega\n",
        "\n",
        "        raise NotImplementedError(\"Derivative for substitute relation currently not implemented.\")\n",
        "##############################################################\n",
        "    def _evaluate_internals_w_replace(self,\n",
        "            x: typing.Sequence[float], compute_derivative: typing.Optional[bool]=False\n",
        "        ) -> typing.Union[np.array, typing.Tuple[np.array, np.array]]:\n",
        "        sigma = self.sigma\n",
        "        m = self.m\n",
        "        n = self.n\n",
        "\n",
        "        sigma_sq = sigma**2\n",
        "        l_seq = np.linspace(0, m, m + 1)\n",
        "        \n",
        "        c_l = (1/n)**l_seq * (1-1/n)**(m-l_seq) * scipy.special.binom(m, l_seq) * np.exp(-l_seq**2/(2*sigma_sq))\n",
        "        w1 = c_l*(l_seq/sigma_sq)\n",
        "\n",
        "        def f_X(t):\n",
        "          return ((1 / np.sqrt(2 * np.pi * sigma_sq) ) * \n",
        "          np.sum((1/n)**l_seq * (1-1/n)**(m-l_seq) * scipy.special.binom(m, l_seq) * np.exp(-(t-l_seq)**2/(2*sigma_sq))))\n",
        "\n",
        "        def dL_t(t):\n",
        "          return (np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq, b=w1)-\n",
        "                         scipy.special.logsumexp(t*l_seq/sigma_sq, b=c_l)) +\n",
        "                  np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq, b=w1)-\n",
        "                         scipy.special.logsumexp(-t*l_seq/sigma_sq, b=c_l)) \n",
        "          )\n",
        "        # newton -> L_eqn dL_t alternating\n",
        "        root_t = np.zeros_like(x)\n",
        "        ALinvx = np.zeros_like(x)\n",
        "        print(x)\n",
        "        if isinstance(x,float)==True:\n",
        "            def L_eqn_single(t):\n",
        "                return (scipy.special.logsumexp(t*l_seq/sigma_sq,b=c_l) - \n",
        "                        scipy.special.logsumexp(-t*l_seq/sigma_sq,b=c_l) - x)\n",
        "            root_single=scipy.optimize.newton(L_eqn_single, 4.0, maxiter=100,fprime=dL_t)  # L^{-1}(s)\n",
        "            ALinvx_single = f_X(root_single)  #  f_X(L^{-1}(s))\n",
        "            increment = 0.0002\n",
        "            def L_eqn_incre(t):\n",
        "                return (scipy.special.logsumexp(t*l_seq/sigma_sq,b=c_l) - \n",
        "                        scipy.special.logsumexp(-t*l_seq/sigma_sq,b=c_l) - (x + increment))\n",
        "            root_incre=scipy.optimize.newton(L_eqn_incre, 4.0, maxiter=100,fprime=dL_t)  # L^{-1}(s+dx)\n",
        "            dLinvx_single = (root_incre - root_single)/increment\n",
        "            omega = ALinvx_single * dLinvx_single\n",
        "\n",
        "        else:\n",
        "            for s in range(len(x)):\n",
        "                def L_eqn(t):\n",
        "                    return (scipy.special.logsumexp(t*l_seq/sigma_sq,b=c_l) - \n",
        "                         scipy.special.logsumexp(-t*l_seq/sigma_sq,b=c_l) - x[s])\n",
        "\n",
        "                root_t[s] = scipy.optimize.newton(L_eqn, 4.0, maxiter=100,fprime=dL_t)  # L^{-1}(s)\n",
        "                ALinvx[s] = f_X(root_t[s])  # f_X(L^{-1}(s))\n",
        "\n",
        "\n",
        "            numerical_d = np.zeros_like(x) \n",
        "            dx=(x[2]-x[1]) \n",
        "            numerical_d = np.diff(root_t)/dx   #  numerical approximation of a derivative\n",
        "            dLinvx= np.append(numerical_d,numerical_d[-1]) # d/ds L^{-1}(s)\n",
        "            omega = np.zeros_like(x)\n",
        "            omega = ALinvx * dLinvx\n",
        "\n",
        "\n",
        "        #omega = np.zeros_like(x)\n",
        "        #omega = ALinvx * dLinvx\n",
        "\n",
        "        if not compute_derivative:\n",
        "            return omega\n",
        "\n",
        "        raise NotImplementedError(\"Derivative for sampling with replacement currently not implemented.\")\n",
        "####(2)#########################################################\n",
        "\n",
        "    def _evaluate_internals_s_h(self,\n",
        "            x: typing.Sequence[float], compute_derivative: typing.Optional[bool]=False\n",
        "        ) -> typing.Union[np.array, typing.Tuple[np.array, np.array]]:\n",
        "        sigma = self.sigma\n",
        "        m = self.m\n",
        "        n = self.n\n",
        "        sizeb = self.sizeb\n",
        "\n",
        "        sigma_sq = sigma**2\n",
        "        l_seq = np.linspace(0, m, m + 1)\n",
        "        \n",
        "        c_l = (sizeb/n)*(1/sizeb)**l_seq * (1-1/sizeb)**(m-l_seq) * scipy.special.binom(m, l_seq) * np.exp(-l_seq**2/(2*sigma_sq))\n",
        "        w1 = c_l*(l_seq/sigma_sq)\n",
        "\n",
        "        def f_X(t):\n",
        "          return ((1 / np.sqrt(2 * np.pi * sigma_sq) ) * (sizeb/n) *\n",
        "          np.sum((1/sizeb)**l_seq * (1-1/sizeb)**(m-l_seq) * scipy.special.binom(m, l_seq) * np.exp(-(t-l_seq)**2/(2*sigma_sq)))+\n",
        "          (1 / np.sqrt(2 * np.pi * sigma_sq) )*(1-sizeb/n)*np.exp(-t**2/(2*sigma_sq)))\n",
        "\n",
        "        def dL_t(t):\n",
        "          return (np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq, b=w1)-\n",
        "                         np.log(np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq, b=c_l))+1-sizeb/n)) +\n",
        "                  np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq, b=w1)-\n",
        "                          np.log(np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq, b=c_l))+1-sizeb/n)) ) \n",
        "          \n",
        "        # newton -> L_eqn dL_t alternating\n",
        "        root_t = np.zeros_like(x)\n",
        "        ALinvx = np.zeros_like(x)\n",
        "        print(x)\n",
        "        if isinstance(x,float)==True:\n",
        "            def L_eqn_single(t):\n",
        "                return (np.log(np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq,b=c_l))+1-sizeb/n) - \n",
        "                        np.log(np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq,b=c_l))+1-sizeb/n) - x)\n",
        "            root_single=scipy.optimize.newton(L_eqn_single, x*10, maxiter=200)  # L^{-1}(s) ,fprime=dL_t\n",
        "            ALinvx_single = f_X(root_single)  #  f_X(L^{-1}(s))\n",
        "            increment = 0.00002\n",
        "            def L_eqn_incre(t):              \n",
        "                return (np.log(np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq,b=c_l))+1-sizeb/n) - \n",
        "                        np.log(np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq,b=c_l))+1-sizeb/n)- (x + increment))\n",
        "            root_incre=scipy.optimize.newton(L_eqn_incre, x*10, maxiter=200)  # L^{-1}(s+dx)  ,fprime=dL_t\n",
        "            dLinvx_single = (root_incre - root_single)/increment\n",
        "            omega = ALinvx_single * dLinvx_single\n",
        "\n",
        "        else:\n",
        "            for s in range(len(x)):\n",
        "                def L_eqn(t):\n",
        "                    return (np.log(np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq,b=c_l))+1-sizeb/n) - \n",
        "                        np.log(np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq,b=c_l))+1-sizeb/n)- x[s])\n",
        "\n",
        "                root_t[s] = scipy.optimize.newton(L_eqn, 10*x[s], maxiter=200)  # L^{-1}(s)  ,fprime=dL_t\n",
        "                ALinvx[s] = f_X(root_t[s])  # f_X(L^{-1}(s))\n",
        "\n",
        "\n",
        "            numerical_d = np.zeros_like(x) \n",
        "            dx=(x[2]-x[1]) \n",
        "            numerical_d = np.diff(root_t)/dx   #  numerical approximation of a derivative\n",
        "            dLinvx= np.append(numerical_d,numerical_d[-1]) # d/ds L^{-1}(s)\n",
        "            omega = np.zeros_like(x)\n",
        "            omega = ALinvx * dLinvx\n",
        "\n",
        "\n",
        "        #omega = np.zeros_like(x)\n",
        "        #omega = ALinvx * dLinvx\n",
        "\n",
        "        if not compute_derivative:\n",
        "            return omega\n",
        "\n",
        "        raise NotImplementedError(\"Derivative for sampling with replacement currently not implemented.\")\n",
        "\n",
        "    def evaluate(self, x: typing.Sequence[float]) -> np.ndarray:\n",
        "        \"\"\" Evaluates the probability densitiy function.\n",
        "\n",
        "        Args:\n",
        "            - x: Privacy loss values for which to compute the probability density.\n",
        "        Returns:\n",
        "            np.ndarray containing the probability density values of\n",
        "                the PLD for each value in `x`\n",
        "        \"\"\"\n",
        "        return self._evaluate_internals(x, compute_derivative=False)\n",
        "\n",
        "    def evaluate_derivative(self, x: typing.Sequence[float]) -> np.ndarray:\n",
        "        \"\"\" Evaluates the derivative of the probability densitiy function.\n",
        "\n",
        "        Args:\n",
        "            - x: Privacy loss values for which to compute the derivate of the\n",
        "                probability density functions.\n",
        "        Returns:\n",
        "            np.ndarray containing the values of the derivative of the probability\n",
        "                densitiy function evaluated each value in `x`\n",
        "        \"\"\"\n",
        "        return self._evaluate_internals(x, compute_derivative=True)[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir4dgoBZSgwN",
        "outputId": "3cc6e3be-2881-4f72-c183-ce7f41cd2d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.4]\n",
            "1\n",
            "0\n",
            "0.4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x=0.4\n",
        "if isinstance(x,float)==True:\n",
        "   x=np.array([x])\n",
        "print(x)\n",
        "print(x.ndim)\n",
        "for s in range(len(x)):\n",
        "  print(s)\n",
        "  print(x[s])\n",
        "numerical_d = np.zeros_like(x) \n",
        "numerical_d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGzfmr85d0wo"
      },
      "outputs": [],
      "source": [
        "class DiscretePrivacyLossDistribution(PrivacyLossDistribution):\n",
        "    \"\"\" The privacy loss distribution defined by two discrete probability mass functions. \"\"\"\n",
        "\n",
        "    def __init__(self, p1: typing.Sequence[float], p2: typing.Sequence[float]) -> None:\n",
        "        \"\"\"\n",
        "        Creates a new instance of DiscretePrivacyLossDistribution given\n",
        "        probability mass functions represented as probability vectors `p1` and `p2`.\n",
        "\n",
        "        It is required that values in `p1` and `p2` correspond to the same event/outcome,\n",
        "        i.e., if `p1[i]` gives probability for some event `x` according to the first\n",
        "        distribution, `p2[i]` must give the probability for the same event.\n",
        "\n",
        "        Args:\n",
        "            - p1: Sequence of probabilities expressing the probability mass\n",
        "                function of the first distribution.\n",
        "            - p2: Sequence of probabilities expressing the probability mass\n",
        "                function of the second distribution.\n",
        "        \"\"\"\n",
        "        if np.size(p1) != np.size(p2):\n",
        "            raise ValueError(\"Both probability mass distributions must have the same size.\")\n",
        "\n",
        "        self._p1 = np.array(p1)\n",
        "        self._p2 = np.array(p2)\n",
        "\n",
        "    def get_accountant_parameters(self, error_tolerance: float) -> typing.Tuple[float, float, int]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @property\n",
        "    def privacy_loss_values(self) -> np.ndarray:\n",
        "        \"\"\" The values of the privacy loss random variable over the DP mechanisms output domain.\n",
        "\n",
        "        Not ordered and may contain duplicates.\n",
        "        \"\"\"\n",
        "        return np.log(self._p1 / self._p2)\n",
        "\n",
        "    @property\n",
        "    def privacy_loss_probabilities(self) -> np.ndarray:\n",
        "        \"\"\" The probability mass omega associated with each privacy loss value. \"\"\"\n",
        "        return self._p1\n",
        "\n",
        "    def discretize_privacy_loss_distribution(self,\n",
        "            start: float, stop: float, num_discretisation_bins_half: int\n",
        "        ) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        nx = 2 * num_discretisation_bins_half\n",
        "        dx = (stop - start) / nx\n",
        "\n",
        "        Lxs = self.privacy_loss_values\n",
        "        ps = self.privacy_loss_probabilities\n",
        "\n",
        "        omega_y_R = np.zeros(nx)\n",
        "        iis = np.ceil((Lxs - start) / dx).astype(int)\n",
        "        assert np.all((iis >= 0) & (iis < nx))\n",
        "        np.add.at(omega_y_R, iis, ps)\n",
        "\n",
        "        # note(lumip): the above is just a histogram computation, but currently does not fit neatly to np.histogram\n",
        "        # because we are dealing with rightmost bin a bit oddly AND np.histogram includes rightmost border for some reason\n",
        "        # which we (probably) don't want\n",
        "\n",
        "        omega_y_L = np.zeros(nx)\n",
        "        iis = np.floor((Lxs - start) / dx).astype(int)\n",
        "        assert np.all((iis >= 0) & (iis < nx))\n",
        "        np.add.at(omega_y_L, iis, ps)\n",
        "\n",
        "        Xn = np.linspace(start, stop, nx, endpoint=False)\n",
        "        return omega_y_L, omega_y_R, Xn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D84VvjjNaAlt"
      },
      "outputs": [],
      "source": [
        "def _get_ps_and_Lxs(\n",
        "        pld: PrivacyLossDistribution, omegas: np.ndarray, omega_Lxs: np.ndarray\n",
        "    ) -> typing.Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\" Get the best representation of privacy loss probability mass for computing\n",
        "        error term.\n",
        "\n",
        "    For computation of the delta error term, these are not required to be discretised\n",
        "    to regular intervals, so more efficient representations are possible.\n",
        "\n",
        "    Args:\n",
        "        - pld: Privacy loss distribution instance.\n",
        "        - omegas: Discretized privacy loss probability masses.\n",
        "        - omega_Lxs: Probability loss values corresponding to positions in `omegas`.\n",
        "\n",
        "    Returns:\n",
        "        - ps: Probability mass function for privacy loss values.\n",
        "        - Lxs: The corresponding privacy loss values.\n",
        "    \"\"\"\n",
        "    # todo(lumip): This should ideally be bundled in the error computation,\n",
        "    #   but that would make that function's interface quite bloated, which indicates\n",
        "    #   it should be part of PLD classes. However, that would in turn strongly\n",
        "    #   couple those with the accountant computations - tricky...\n",
        "\n",
        "    if isinstance(pld, DiscretePrivacyLossDistribution):\n",
        "        # if pld is a DiscretePrivacyLossDistribution we can get\n",
        "        #  privacy loss values and corresponding probabilities directly for\n",
        "        #  the error computation and don't need to rely on the discretisation.\n",
        "        # these will typically be smaller arrays and thus faster to compute on.\n",
        "        Lxs = pld.privacy_loss_values\n",
        "        ps = pld.privacy_loss_probabilities\n",
        "    else:\n",
        "        ps = omegas\n",
        "        Lxs = omega_Lxs\n",
        "\n",
        "    return ps, Lxs\n",
        "\n",
        "def _get_delta_error_term(\n",
        "        Lxs: typing.Sequence[float],\n",
        "        ps: typing.Sequence[float],\n",
        "        num_compositions: int = 500,\n",
        "        L: float = 20.0,\n",
        "        lambd: typing.Optional[float] = None\n",
        "    ) -> float:\n",
        "    \"\"\" Computes the total error term for δ computed by the Fourier accountant\n",
        "    for repeated application of a privacy mechanism.\n",
        "\n",
        "    The computation follows Theorem 7 in Koskela & Honkela, \"Computing Differential Privacy for\n",
        "    Heterogeneous Compositions Using FFT\", 2021, arXiv preprint, https://arxiv.org/abs/2102.12412 .\n",
        "\n",
        "    Args:\n",
        "        - Lxs: Sequence of privacy loss values.\n",
        "        - ps: Sequence of privacy loss probability masses.\n",
        "        - num_compositions: The number of compositions (=applications) of the privacy mechanism.\n",
        "        - L: The truncation threshold (in privacy loss space) used by the accountant.\n",
        "        - lambd: The parameter λ for error estimation.\n",
        "    \"\"\"\n",
        "\n",
        "    if lambd is None:\n",
        "        lambd = .5 * L\n",
        "\n",
        "    assert np.size(ps) == np.size(Lxs)\n",
        "    nonzero_probability_filter = ~np.isclose(ps, 0)\n",
        "    ps = ps[nonzero_probability_filter]\n",
        "    Lxs = Lxs[nonzero_probability_filter]\n",
        "    assert np.all(ps > 0)\n",
        "\n",
        "    # Compute the lambda-divergence \\alpha^+\n",
        "    alpha_plus = scipy.special.logsumexp(np.log(ps) + lambd * Lxs)\n",
        "\n",
        "    # Compute the lambda-divergence \\alpha^-\n",
        "    alpha_minus = scipy.special.logsumexp(np.log(ps) - lambd * Lxs)\n",
        "\n",
        "    k = num_compositions\n",
        "\n",
        "    common_factor_log = -(L * lambd + np.log1p(-np.exp(-2 * L * lambd)))\n",
        "\n",
        "    T1_log = k * alpha_plus + common_factor_log\n",
        "    T2_log = k * alpha_minus + common_factor_log\n",
        "\n",
        "    T_max_log = np.maximum(T1_log, T2_log)\n",
        "\n",
        "    error_term = np.exp(T_max_log) * (np.exp(T1_log - T_max_log) + np.exp(T2_log - T_max_log))\n",
        "\n",
        "    return error_term\n",
        "\n",
        "def _delta_fft_computations(omegas: np.ndarray, num_compositions: int) -> np.ndarray:\n",
        "    \"\"\" Core computation of privacy loss distribution convolutions using FFT.\n",
        "\n",
        "    Args:\n",
        "        - omegas: Numpy array of probability masses omega for discrete bins of privacy loss values\n",
        "            for a single invocation of a privacy mechanism.\n",
        "        - num_compositions: The number of sequential invocations of the privacy mechanism.\n",
        "    Returns:\n",
        "        - Numpy array of probability masses for the discrete bins of privacy loss values\n",
        "            after `num_compositions` sequential invocations of the privacy mechanisms\n",
        "            characterized by `omegas`.\n",
        "    \"\"\"\n",
        "    # Flip omegas, i.e. fx <- D(omega_y), the matrix D = [0 I;I 0]\n",
        "    nx = len(omegas)\n",
        "    assert nx % 2 == 0\n",
        "    half = nx // 2\n",
        "    fx = np.concatenate((omegas[half:], omegas[:half]))\n",
        "    assert np.size(fx) == np.size(omegas)\n",
        "\n",
        "    # Compute the DFT\n",
        "    FF1 = np.fft.rfft(fx)\n",
        "\n",
        "    # Take elementwise powers and compute the inverse DFT\n",
        "    cfx = np.real(np.fft.irfft((FF1 ** num_compositions)))\n",
        "\n",
        "    # Flip again, i.e. cfx <- D(cfx), D = [0 I;I 0]\n",
        "    cfx = np.concatenate((cfx[half:], cfx[:half]))\n",
        "\n",
        "    return cfx # todo(lumip): there are sometimes values < 0, all quite small, probably should be 0 but numerical precision strikes... problem?\n",
        "\n",
        "def _compute_delta(\n",
        "        convolved_omegas: np.ndarray, target_eps: float, L: float, compute_derivative: bool=False\n",
        "    ) -> typing.Union[float, typing.Tuple[float, float]]:\n",
        "    \"\"\" Compute delta from privacy loss probability masses.\n",
        "\n",
        "    Args:\n",
        "        - convolved_omegas: Numpy array of probability masses after convolving all\n",
        "            privacy mechanism invocations.\n",
        "        - target_eps: The targeted epsilon to compute delta for.\n",
        "        - L: The bound for the discretisation interval.\n",
        "        - compute_derivative: If True, additionally return the derivative of delta with\n",
        "            respect to epsilon.\n",
        "\n",
        "    Returns:\n",
        "        - delta: The computed delta.\n",
        "        - ddelta (Optional, if `compute_derivative = True`): The derivative of delta wrt epsilon.\n",
        "    \"\"\"\n",
        "    nx = len(convolved_omegas)\n",
        "    # Evaluate \\delta(target_eps)\n",
        "    x = np.linspace(-L, L, nx, endpoint=False) # grid for the numerical integration\n",
        "    integral_mask = x > target_eps\n",
        "    x = x[integral_mask]\n",
        "    convolved_omegas = convolved_omegas[integral_mask]\n",
        "\n",
        "    dexp_e = -np.exp(target_eps - x)\n",
        "    exp_e = 1 + dexp_e\n",
        "    assert np.all(exp_e > 0)\n",
        "\n",
        "    integrand = exp_e * convolved_omegas\n",
        "    assert np.all(~(integrand < 0 ) | np.isclose(integrand, 0)), \"encountered negative values in pld after composition\"\n",
        "\n",
        "    delta = np.sum(integrand)\n",
        "\n",
        "    if not compute_derivative:\n",
        "        return delta\n",
        "\n",
        "    dintegrand = dexp_e * convolved_omegas\n",
        "    ddelta = np.sum(dintegrand)\n",
        "    return delta, ddelta\n",
        "\n",
        "def get_delta_upper_bound(\n",
        "        pld: PrivacyLossDistribution,\n",
        "        target_eps: float,\n",
        "        num_compositions: int,\n",
        "        num_discretisation_bins_half: int = int(1E6),\n",
        "        L: float = 20.0\n",
        "    ):\n",
        "    \"\"\" Computes the upper bound for privacy parameter δ for repeated application\n",
        "    of a privacy mechanism.\n",
        "\n",
        "    The computation follows the Fourier accountant method described in Koskela et al.,\n",
        "    \"Tight Differential Privacy for Discrete-Valued Mechanisms and for the Subsampled\n",
        "    Gaussian Mechanism Using FFT\", Proceedings of The 24th International Conference\n",
        "    on Artificial Intelligence and Statistics, PMLR 130:3358-3366, 2021.\n",
        "\n",
        "    Args:\n",
        "        - pld: The privacy loss distribution of a single application of the privacy mechanism.\n",
        "        - target_eps: The privacy parameter ε for which to compute δ.\n",
        "        - num_compositions: The number of compositions (=applications) of the privacy mechanism.\n",
        "        - num_discretisation_bins_half: The number of discretisation bins used by the accountant, divided by 2.\n",
        "        - L: The truncation threshold (in privacy loss space) used by the accountant.\n",
        "    \"\"\"\n",
        "    # obtain discretized privacy loss densities\n",
        "    _, omega_y, Lxs = pld.discretize_privacy_loss_distribution(-L, L, num_discretisation_bins_half)\n",
        "\n",
        "    # compute delta\n",
        "    convolved_omegas = _delta_fft_computations(omega_y, num_compositions)\n",
        "    delta = _compute_delta(convolved_omegas, target_eps, L)\n",
        "\n",
        "    ps, Lxs = _get_ps_and_Lxs(pld, omega_y, Lxs)\n",
        "\n",
        "    error_term = _get_delta_error_term(Lxs, ps, num_compositions, L)\n",
        "    delta += error_term\n",
        "\n",
        "    return np.clip(delta, 0., 1.)\n",
        "\n",
        "def get_delta_lower_bound(\n",
        "        pld: PrivacyLossDistribution,\n",
        "        target_eps: float,\n",
        "        num_compositions: int,\n",
        "        num_discretisation_bins_half: int = int(1E6),\n",
        "        L: float = 20.0\n",
        "    ):\n",
        "    \"\"\" Computes the lower bound for privacy parameter δ for repeated application\n",
        "    of a privacy mechanism.\n",
        "\n",
        "    The computation follows the Fourier accountant method described in Koskela et al.,\n",
        "    \"Tight Differential Privacy for Discrete-Valued Mechanisms and for the Subsampled\n",
        "    Gaussian Mechanism Using FFT\", Proceedings of The 24th International Conference\n",
        "    on Artificial Intelligence and Statistics, PMLR 130:3358-3366, 2021.\n",
        "\n",
        "    Args:\n",
        "        - pld: The privacy loss distribution of a single application of the privacy mechanism.\n",
        "        - target_eps: The privacy parameter ε for which to compute δ.\n",
        "        - num_compositions: The number of compositions (=applications) of the privacy mechanism.\n",
        "        - num_discretisation_bins_half: The number of discretisation bins used by the accountant, divided by 2.\n",
        "        - L: The truncation threshold (in privacy loss space) used by the accountant.\n",
        "    \"\"\"\n",
        "    # obtain discretized privacy loss densities\n",
        "    omega_y_L, omega_y_R, Lxs = pld.discretize_privacy_loss_distribution(-L, L, num_discretisation_bins_half)\n",
        "\n",
        "    # compute delta\n",
        "    convolved_omegas = _delta_fft_computations(omega_y_L, num_compositions)\n",
        "    delta = _compute_delta(convolved_omegas, target_eps, L)\n",
        "\n",
        "    ps, Lxs = _get_ps_and_Lxs(pld, omega_y_R, Lxs) # note(lumip): bounds probabilities from above (for truncated region),\n",
        "                       # which seems more appropriate for the error term than bounding from below\n",
        "                       # todo(all): verify this makes sense\n",
        "\n",
        "    error_term = _get_delta_error_term(Lxs, ps, num_compositions, L)\n",
        "    delta -= error_term\n",
        "\n",
        "    return np.clip(delta, 0., 1.)\n",
        "\n",
        "def _compute_epsilon(\n",
        "        convolved_omegas: np.ndarray, target_delta: float, tol: float, error_term: float, L: float\n",
        "    ) -> typing.Tuple[float, float]:\n",
        "    \"\"\" Find epsilon using Newton iteration on delta computation for given probability masses.\n",
        "\n",
        "    Args:\n",
        "        - convolved_omegas: Numpy array of probability masses after convolving all\n",
        "            privacy mechanism invocations.\n",
        "        - target_delta: The targeted delta to compute epsilon for.\n",
        "        - tol: Optimisation cutoff threshold for epsilon.\n",
        "        - error_term: Delta error term.\n",
        "        - L: The bound for the discretisation interval.\n",
        "\n",
        "    Returns:\n",
        "        - epsilon: The computed value for epsilon.\n",
        "        - delta: The value of delta corresponding to epsilon. Might differ from\n",
        "            `target_delta` if a suitable epsilon for `target_delta` cannot be found.\n",
        "    \"\"\"\n",
        "\n",
        "    last_epsilon = -np.inf\n",
        "    epsilon = 0\n",
        "    delta, ddelta = _compute_delta(convolved_omegas, epsilon, L, compute_derivative=True)\n",
        "    delta += error_term\n",
        "    delta = np.clip(delta, 0., 1.)\n",
        "    while np.abs(target_delta - delta) > tol and not np.isclose(epsilon, last_epsilon):\n",
        "        f_e = delta - target_delta\n",
        "        df_e = ddelta\n",
        "        last_epsilon = epsilon\n",
        "        epsilon = np.maximum(last_epsilon - f_e/df_e, 0)\n",
        "\n",
        "        delta, ddelta = _compute_delta(convolved_omegas, epsilon, L, compute_derivative=True)\n",
        "        delta += error_term\n",
        "        delta = np.clip(delta, 0., 1.)\n",
        "\n",
        "    return epsilon, delta\n",
        "\n",
        "def get_epsilon_upper_bound(\n",
        "        pld: PrivacyLossDistribution,\n",
        "        target_delta: float,\n",
        "        num_compositions: int,\n",
        "        num_discretisation_bins_half: int = int(1E6),\n",
        "        L: float = 20.0,\n",
        "        tol: float = 1e-9\n",
        "    ):\n",
        "    \"\"\" Computes the upper bound for privacy parameter ε for repeated application\n",
        "    of a privacy mechanism.\n",
        "\n",
        "    The computation optimizes for ε iteratively using the Newton method on\n",
        "    the Fourier accountant for computing an upper bound for δ.\n",
        "    The accountant is described in Koskela et al.,\n",
        "    \"Tight Differential Privacy for Discrete-Valued Mechanisms and for the Subsampled\n",
        "    Gaussian Mechanism Using FFT\", Proceedings of The 24th International Conference\n",
        "    on Artificial Intelligence and Statistics, PMLR 130:3358-3366, 2021.\n",
        "\n",
        "    Args:\n",
        "        - pld: The privacy loss distribution of a single application of the privacy mechanism.\n",
        "        - target_delta: The privacy parameter δ for which to compute ε.\n",
        "        - num_compositions: The number of compositions (=applications) of the privacy mechanism.\n",
        "        - num_discretisation_bins_half: The number of discretisation bins used by the accountant, divided by 2.\n",
        "        - L: The truncation threshold (in privacy loss space) used by the accountant.\n",
        "        - tol: Error tolerance for ε.\n",
        "    \"\"\"\n",
        "    # obtain discretized privacy loss densities\n",
        "    omega_y_L, omega_y_R, Lxs = pld.discretize_privacy_loss_distribution(-L, L, num_discretisation_bins_half)\n",
        "\n",
        "    # compute convolved omegas\n",
        "    convolved_omegas = _delta_fft_computations(omega_y_R, num_compositions)\n",
        "\n",
        "    ps, Lxs = _get_ps_and_Lxs(pld, omega_y_R, Lxs)\n",
        "    error_term = _get_delta_error_term(Lxs, ps, num_compositions, L)\n",
        "\n",
        "    epsilon, delta = _compute_epsilon(convolved_omegas, target_delta, tol, error_term, L)\n",
        "\n",
        "    if epsilon > L: raise ValueError(\"The evaluation bound L for privacy loss is too small.\")\n",
        "    if delta > target_delta + tol: raise PrivacyException(\"Could not find an epsilon for the given target delta.\")\n",
        "    assert epsilon >= 0., \"Computed negative epsilon!\"\n",
        "\n",
        "    return epsilon, delta\n",
        "\n",
        "def get_epsilon_lower_bound(\n",
        "        pld: PrivacyLossDistribution,\n",
        "        target_delta: float,\n",
        "        num_compositions: int,\n",
        "        num_discretisation_bins_half: int = int(1E6),\n",
        "        L: float = 20.0,\n",
        "        tol: float = 1e-9\n",
        "    ):\n",
        "    \"\"\" Computes the lower bound for privacy parameter ε for repeated application\n",
        "    of a privacy mechanism.\n",
        "\n",
        "    The computation optimizes for ε iteratively using the Newton method on\n",
        "    the Fourier accountant for computing a lower bound for δ.\n",
        "    The accountant is described in Koskela et al.,\n",
        "    \"Tight Differential Privacy for Discrete-Valued Mechanisms and for the Subsampled\n",
        "    Gaussian Mechanism Using FFT\", Proceedings of The 24th International Conference\n",
        "    on Artificial Intelligence and Statistics, PMLR 130:3358-3366, 2021.\n",
        "\n",
        "    Args:\n",
        "        - pld: The privacy loss distribution of a single application of the privacy mechanism.\n",
        "        - target_delta: The privacy parameter δ for which to compute ε.\n",
        "        - num_compositions: The number of compositions (=applications) of the privacy mechanism.\n",
        "        - num_discretisation_bins_half: The number of discretisation bins used by the accountant, divided by 2.\n",
        "        - L: The truncation threshold (in privacy loss space) used by the accountant.\n",
        "        - tol: Error tolerance for ε.\n",
        "    \"\"\"\n",
        "    # obtain discretized privacy loss densities\n",
        "    omega_y_L, omega_y_R, Lxs = pld.discretize_privacy_loss_distribution(-L, L, num_discretisation_bins_half)\n",
        "\n",
        "    # compute convolved omegas\n",
        "    convolved_omegas = _delta_fft_computations(omega_y_L, num_compositions)\n",
        "\n",
        "    ps, Lxs = _get_ps_and_Lxs(pld, omega_y_R, Lxs)\n",
        "\n",
        "    error_term = _get_delta_error_term(Lxs, ps, num_compositions, L)\n",
        "\n",
        "    epsilon, delta = _compute_epsilon(convolved_omegas, target_delta, tol, -error_term, L)\n",
        "\n",
        "    if epsilon > L: raise ValueError(\"The evaluation bound L for privacy loss is too small.\")\n",
        "    if delta > target_delta + tol: raise PrivacyException(f\"Could not find an epsilon for the given target delta {target_delta}.\")\n",
        "    assert epsilon >= 0., \"Computed negative epsilon!\"\n",
        "\n",
        "    return epsilon, delta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYyqE4NFZoBC"
      },
      "outputs": [],
      "source": [
        "ncomp = 10000 # number of compositions of DP queries over minibatches = number of iterations of SGD\n",
        "q     = 0.01  # subsampling ratio of minibatch\n",
        "sigma = 4.0   # noise level for each query\n",
        "\n",
        "# computing privacy parameters for given parameters in remove/add neighboring relation with\n",
        "#  poisson subsampling of minibatches\n",
        "pld = SubsampledGaussianMechanism(\n",
        "    sigma, q, NeighborRelation.REMOVE_POISSON\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ixm9H2hpnQv",
        "outputId": "b02920c4-0864-4391-bf07-9b966ab240d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-43.522240507938335"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sizeb=b\n",
        "sigma_sq = sigma**2\n",
        "l_seq = np.linspace(0, m, m + 1)\n",
        "x= -10\n",
        "        \n",
        "c_l = (sizeb/n)*(1/sizeb)**l_seq * (1-1/sizeb)**(m-l_seq) * scipy.special.binom(m, l_seq) * np.exp(-l_seq**2/(2*sigma_sq))\n",
        "w1 = c_l*(l_seq/sigma_sq)\n",
        "\n",
        "def f_X(t):\n",
        "        return ((1 / np.sqrt(2 * np.pi * sigma_sq) ) * (sizeb/n) *\n",
        "        np.sum((1/sizeb)**l_seq * (1-1/sizeb)**(m-l_seq) * scipy.special.binom(m, l_seq) * np.exp(-(t-l_seq)**2/(2*sigma_sq)))+\n",
        "         (1 / np.sqrt(2 * np.pi * sigma_sq) )*(1-sizeb/n)*np.exp(-t**2/(2*sigma_sq)))\n",
        "\n",
        "def f_Y(t):\n",
        "          return ((1 / np.sqrt(2 * np.pi * sigma_sq) ) * (sizeb/n) *\n",
        "          np.sum((1/sizeb)**l_seq * (1-1/sizeb)**(m-l_seq) * scipy.special.binom(m, l_seq) * np.exp(-(t+l_seq)**2/(2*sigma_sq)))+\n",
        "          (1 / np.sqrt(2 * np.pi * sigma_sq) )*(1-sizeb/n)*np.exp(-t**2/(2*sigma_sq)))\n",
        "\n",
        "def dL_t(t):\n",
        "          return (np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq, b=w1)-\n",
        "                         np.log(np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq, b=c_l))+1-sizeb/n)) +\n",
        "                  np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq, b=w1)-\n",
        "                          np.log(np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq, b=c_l))+1-sizeb/n)) ) \n",
        "          \n",
        "        # newton -> L_eqn dL_t alternating\n",
        "\n",
        "def L_eqn_single(t):\n",
        "              return (np.log(f_X(t)/f_Y(t)) - x)\n",
        "#                return (np.log(np.exp(scipy.special.logsumexp(t*l_seq/sigma_sq,b=c_l))+1-sizeb/n) - \n",
        "#                        np.log(np.exp(scipy.special.logsumexp(-t*l_seq/sigma_sq,b=c_l))+1-sizeb/n) - x)\n",
        "root_single=scipy.optimize.newton(L_eqn_single, -100, maxiter=1000,fprime=dL_t)  # L^{-1}(s) ,fprime=dL_t\n",
        "root_single"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9lkw6gis_pl"
      },
      "outputs": [],
      "source": [
        "ncomp = 1500 # number of compositions of DP queries over minibatches = number of iterations of SGD\n",
        "sigma = 4.0   # noise level for each query\n",
        "m=200\n",
        "b=118\n",
        "n=10000\n",
        "q=0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y3kEJ2ouSbw"
      },
      "outputs": [],
      "source": [
        "pld = SubsampledGaussianMechanism(\n",
        "    sigma, q, NeighborRelation.REMOVE_POISSON\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dNOtmEYtM_u"
      },
      "outputs": [],
      "source": [
        "pld = SubsampledGaussianMechanism(\n",
        "    sigma, q, NeighborRelation.SUBSTITUTE_NO_REPLACE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re6g0o-p_jgg"
      },
      "outputs": [],
      "source": [
        "pld = SubsampledGaussianWithReplace(\n",
        "    sigma, m,n,b, NeighborRelation.S_W_REPLACE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNY15L54_gbV"
      },
      "outputs": [],
      "source": [
        "pld = SubsampledGaussianWithReplace(\n",
        "    sigma, m,n,b, NeighborRelation.S_H\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zchAJpBodd5z",
        "outputId": "b0d10815-8168-43c1-ae2c-0cffcaef1260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-10.       -9.99996  -9.99992 ...   9.99992   9.99996  10.     ]\n",
            "-9.442719098955602e-06\n",
            "9.442719100731952e-06\n",
            "2.1114561800574487e-05\n",
            "1.778122815406159e-05\n",
            "1.4447894556990021e-05\n",
            "[-10.       -9.99996  -9.99992 ...   9.99992   9.99996  10.     ]\n",
            "-9.442719098955602e-06\n",
            "9.442719100731952e-06\n",
            "2.1114561800574487e-05\n",
            "1.778122815406159e-05\n",
            "1.4447894556990021e-05\n",
            "4.2469893931300995e-05 0.019337441507913534\n"
          ]
        }
      ],
      "source": [
        "# computing delta bounds for given epsilon\n",
        "target_eps = 1.0\n",
        "delta_upper = get_delta_upper_bound(\n",
        "    pld, target_eps, ncomp, L=10, num_discretisation_bins_half=int((2.5)*1E5)\n",
        ")\n",
        "delta_lower = get_delta_lower_bound(\n",
        "    pld, target_eps, ncomp, L=10, num_discretisation_bins_half=int((2.5)*1E5)\n",
        ")\n",
        "print(delta_lower, delta_upper)\n",
        "# 1.2282282018518088e-07 0.00010514221537608886"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1UJVg4O9mvcJ",
        "outputId": "654197bb-11d8-42ef-f253-b3d2f5bd5d06"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-a40885fbd745>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ndim'"
          ]
        }
      ],
      "source": [
        "isinstance(0.02,np.float64)\n",
        "print([0.1].ndim)\n",
        "print(np.shape(0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbhYAo5S_qt4",
        "outputId": "21848b3f-e205-484a-cc02-2579eea45f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-10.       -9.99996  -9.99992 ...   9.99992   9.99996  10.     ]\n",
            "3.0557280900208597e-05\n",
            "4.944271910031549e-05\n",
            "1.8885438200106897e-05\n",
            "3.829705626314336e-05\n",
            "4.1630390164513835e-05\n",
            "3.496372236177288e-05\n",
            "[-10.       -9.99996  -9.99992 ...   9.99992   9.99996  10.     ]\n",
            "3.0557280900208597e-05\n",
            "4.944271910031549e-05\n",
            "1.8885438200106897e-05\n",
            "3.829705626314336e-05\n",
            "4.1630390164513835e-05\n",
            "3.496372236177288e-05\n",
            "1.0432550848175894 1.3011705656430181\n"
          ]
        }
      ],
      "source": [
        "# computing epsilon bounds for given delta\n",
        "target_delta = 1e-5\n",
        "eps_upper, _ = get_epsilon_upper_bound(\n",
        "    pld, target_delta, ncomp, L=10, num_discretisation_bins_half=int((2.5)*1E5)\n",
        ")\n",
        "eps_lower, _ = get_epsilon_lower_bound(\n",
        "    pld, target_delta, ncomp, L=10, num_discretisation_bins_half=int((2.5)*1E5)\n",
        ")\n",
        "print(eps_lower, eps_upper)\n",
        "# 0.6980780002786826 1.1339061240664539"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk6DVaw/8m1mRudT4/YuQP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}